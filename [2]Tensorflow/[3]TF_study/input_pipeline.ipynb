{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = [21,22,-108,31,-1,32,34,31] # numpy type, the minus values are erroneous numbers\n",
    "type(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-27 00:01:19.544921: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-27 00:01:19.551980: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (), types: tf.int32>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(numbers) # create a dataset\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(21, shape=(), dtype=int32)\n",
      "tf.Tensor(22, shape=(), dtype=int32)\n",
      "tf.Tensor(-108, shape=(), dtype=int32)\n",
      "tf.Tensor(31, shape=(), dtype=int32)\n",
      "tf.Tensor(-1, shape=(), dtype=int32)\n",
      "tf.Tensor(32, shape=(), dtype=int32)\n",
      "tf.Tensor(34, shape=(), dtype=int32)\n",
      "tf.Tensor(31, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for num in dataset: \n",
    "    print(num) # We can see that the numpy data is converted to tensor type inherently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "-108\n",
      "31\n",
      "-1\n",
      "32\n",
      "34\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "# first way to change the tensor to numpy\n",
    "for num in dataset:\n",
    "    print(num.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TensorSliceDataset' object has no attribute 'as_numpy_iterator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kz/1lfrprk16v1cp9n7y1b41xk80000gn/T/ipykernel_46545/645722740.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# second way to change the tensor to numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_numpy_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# use method as_numpy_iterator()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TensorSliceDataset' object has no attribute 'as_numpy_iterator'"
     ]
    }
   ],
   "source": [
    "# second way to change the tensor to numpy\n",
    "for num in dataset.as_numpy_iterator(): # use method as_numpy_iterator()\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(21, shape=(), dtype=int32)\n",
      "tf.Tensor(22, shape=(), dtype=int32)\n",
      "tf.Tensor(-108, shape=(), dtype=int32)\n",
      "tf.Tensor(31, shape=(), dtype=int32)\n",
      "tf.Tensor(-1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# a useful function to take a certain amount of data from the dataset\n",
    "for num in dataset.take(5):\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(32, shape=(), dtype=int32)\n",
      "tf.Tensor(34, shape=(), dtype=int32)\n",
      "tf.Tensor(31, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# a useful function to skip a certain amount of data from the dataset\n",
    "for num in dataset.skip(5):\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(21, shape=(), dtype=int32)\n",
      "tf.Tensor(22, shape=(), dtype=int32)\n",
      "tf.Tensor(31, shape=(), dtype=int32)\n",
      "tf.Tensor(32, shape=(), dtype=int32)\n",
      "tf.Tensor(34, shape=(), dtype=int32)\n",
      "tf.Tensor(31, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# use filter() method to filter out all the minus values\n",
    "dataset = dataset.filter(lambda x: x > 0) #NOTE: lambda function applies the function to all the element in the list\n",
    "for num in dataset:\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(210, shape=(), dtype=int32)\n",
      "tf.Tensor(220, shape=(), dtype=int32)\n",
      "tf.Tensor(310, shape=(), dtype=int32)\n",
      "tf.Tensor(320, shape=(), dtype=int32)\n",
      "tf.Tensor(340, shape=(), dtype=int32)\n",
      "tf.Tensor(310, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# use map() method to transform the values to a different set of values under a certain criterion\n",
    "dataset = dataset.map(lambda y: y * 10)\n",
    "for num in dataset:\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "## Shuffle elements in the dataset\n",
    "# first way: use shuffle() method of dataset objects\n",
    "# Very interesting experiment of doing shuffle()\n",
    "values = [1 ,2 ,3 , 4, 5, 6, 7]\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices(values) # create a dataset\n",
    "for num in dataset_test:\n",
    "    print(num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step #0: 1\n",
      "step #1: 2\n",
      "step #2: 3\n",
      "step #3: 4\n",
      "step #4: 5\n",
      "step #5: 6\n",
      "step #6: 7\n"
     ]
    }
   ],
   "source": [
    "# Introduction 1.1: buffer() method\n",
    "# If we choose the (random) buffer size to be 1, the number will not be randomized.\n",
    "# because the elements in the list go to the random buffer one by one since the size\n",
    "# of the buffer is only 1. The output is selected from the random buffer one at a time.\n",
    "dataset_test.shuffle(1) \n",
    "for idx , num in enumerate(dataset_test):\n",
    "    print(f'step #{idx}: {num.numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step #0: 2\n",
      "step #1: 3\n",
      "step #2: 1\n",
      "step #3: 5\n",
      "step #4: 6\n",
      "step #5: 7\n",
      "step #6: 4\n"
     ]
    }
   ],
   "source": [
    "# Introduction 1.2: buffer() method\n",
    "# If we choose the (random) buffer size to be 2,\n",
    "# At the first iteration, 1, 2 go into the random buffer, and one number is randomly selected.\n",
    "# Then 3 go into the buffer, and then 4, 5, 6, 7 consecutively.\n",
    "#   #random buffer     #source dataset\n",
    "    # 1st:1 2          3 4 5 6 7   \n",
    "    # output: 2\n",
    "    # 2nd:1 3          4 5 6 7    \n",
    "    # output: 1\n",
    "    # 3rd:3 4          5 6 7     \n",
    "    # output: 4\n",
    "    # 4th:3 5          6 7    \n",
    "    # output: 3\n",
    "    # 5th:5 6          7      \n",
    "    # output: 6\n",
    "    # 6th:5 7          []     \n",
    "    # output: 5\n",
    "    # 7th: 7           []     \n",
    "    # output: 7\n",
    "    \n",
    "# It means that 4 will never be selected before 3rd pick, \n",
    "# 7 will never be selected before 6rd pick because only at that time, \n",
    "# the corresponding value is put into random buffer.\n",
    "\n",
    "## Conclusion: When the random buffer size is larger, the randomization will be superior but slower.\n",
    "# On the contrary, the random buffer size is smaller, the speed is faster while randomization is poorer.\n",
    "values = [1 ,2 ,3 , 4, 5, 6, 7]\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices(values) # create a dataset\n",
    "dataset_test = dataset_test.shuffle(2) #! NOTE: the shuffed dataset has to be assigned to a variable since the change is not inplace.\n",
    "for idx , num in enumerate(dataset_test):\n",
    "    print(f'step #{idx}: {num.numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-15T02:21:51.209550Z",
     "iopub.status.busy": "2022-01-15T02:21:51.208360Z",
     "iopub.status.idle": "2022-01-15T02:21:51.212172Z",
     "shell.execute_reply": "2022-01-15T02:21:51.211725Z"
    },
    "id": "1CL7aB0ahXn_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step #0: 2\n",
      "step #1: 1\n",
      "step #2: 5\n",
      "step #3: 6\n",
      "step #4: 3\n",
      "step #5: 4\n",
      "step #6: 7\n",
      "step #7: 2\n",
      "step #8: 1\n",
      "step #9: 4\n"
     ]
    }
   ],
   "source": [
    "# Introduction 2: repeat() method\n",
    "# It will make dataset re-initialize after each iteration\n",
    "# producing indefinite sequence of elements.\n",
    "# We'll stop after first 10 steps.\n",
    "values = [1 ,2 ,3 , 4, 5, 6, 7]\n",
    "dataset = tf.data.Dataset.from_tensor_slices(values)\n",
    "dataset = dataset.shuffle(buffer_size=3).repeat() # This will make the dataset work as if it has infinite number of elements\n",
    "\n",
    "#NOTE: the for loop will never stop, when all the elements have been iterated. The dataset will be re-initialized and starts\n",
    "# another round of iteration.\n",
    "for idx, elem in enumerate(dataset): \n",
    "  print(f'step #{idx}: {elem.numpy()}')\n",
    "  # dataset will be genearted indefinitely,\n",
    "  # so we'll limit the first 10 elements only\n",
    "  if idx >= 9:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 1\n",
      "1: 2\n",
      "2: 3\n",
      "3: 4\n",
      "4: 5\n",
      "5: 6\n",
      "6: 7\n",
      "batch #0: [1 2 3]\n",
      "batch #1: [4 5 6]\n",
      "batch #2: [7]\n"
     ]
    }
   ],
   "source": [
    "# Introduction 3.1: batch() method\n",
    "values = [1 ,2 ,3 , 4, 5, 6, 7]\n",
    "dataset = tf.data.Dataset.from_tensor_slices(values)\n",
    "for idx, elem in enumerate(dataset):\n",
    "  print(f'{idx}: {elem.numpy()}')\n",
    "\n",
    "dataset = dataset.batch(3)\n",
    "for idx, elem in enumerate(dataset):\n",
    "  print(f'batch #{idx}: {elem.numpy()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch #0: [3 2 4]\n",
      "batch #1: [6 7 1]\n",
      "batch #2: [5 1 4]\n",
      "batch #3: [2 5 6]\n"
     ]
    }
   ],
   "source": [
    "# Introduction 3.2: batch() method\n",
    "# Now we'll add batch() to shuffle() and repeat()\n",
    "# batch() method will take every <size> elements a batch\n",
    "values = [1 ,2 ,3 , 4, 5, 6, 7]\n",
    "dataset = tf.data.Dataset.from_tensor_slices(values)\n",
    "dataset = dataset.shuffle(buffer_size=3).repeat().batch(3) \n",
    "\n",
    "for idx, elem in enumerate(dataset):\n",
    "  print(f'batch #{idx}: {elem.numpy()}')\n",
    "  # Dataset will be genearted indefinitely,\n",
    "  # so we'll limit the first 4 batches only\n",
    "  if idx >= 3:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4  18 120  20]\n",
      "[ 10 200]\n"
     ]
    }
   ],
   "source": [
    "# One single line code to implement \n",
    "# 1. create dataset\n",
    "# 2. filter out undesired values (preprocessing)\n",
    "# 3. map the values to a desired range (resize)\n",
    "# 4. shuffle the dataset\n",
    "# 5. create batches out of the shuffled dataset\n",
    "\n",
    "values = [10 ,2 ,-30 , -4, 5, 60, -70, 9, 100]\n",
    "dataset = tf.data.Dataset.from_tensor_slices(values).filter(lambda x: x > 0).map(lambda y: y * 2).shuffle(4).batch(4)\n",
    "# dataset = tf.data.Dataset.from_tensor_slices(values)\n",
    "# dataset\n",
    "# dataset = dataset.filter(lambda x: x > 0).map(lambda y: y * 2).shuffle(4).batch(4)\n",
    "for num in dataset.as_numpy_iterator():\n",
    "    print(num)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7b48e2873f2bf9fc322f66cbce100259936f291e167d1f147f978241de7630e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('basic_NN_study': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
