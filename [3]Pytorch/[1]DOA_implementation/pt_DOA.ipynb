{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# import tensorflow as tf\n",
    "import scipy.io as sio\n",
    "from scipy.io import loadmat, savemat\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(205000, 400)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileName = 'random_single_source_100snapshots_1000sample'\n",
    "dirc = os.getcwd()\n",
    "dataPath = os.path.join(dirc,fileName)\n",
    "print(os.path.exists(dataPath))\n",
    "data_set = []\n",
    "\n",
    "for root,dirs,files in os.walk(dataPath):\n",
    "    for file in files:\n",
    "        if file=='train_data.mat':\n",
    "            inputPath = os.path.join(root,file)\n",
    "            x_train = sio.loadmat(inputPath)\n",
    "            x_train = x_train['train_data']  # noisy sample covariance matrix\n",
    "            data_set.append(x_train[:x_train.shape[0],:]) #NOTE: put all the train_data of different SNR into one list\n",
    "            break\n",
    "data_train = data_set[0]\n",
    "for i in data_set:\n",
    "    data_train = np.vstack((data_train,i)) # stack all the datasets vertically\n",
    "    \n",
    "data_train = data_train[x_train.shape[0]:] # the first dataset is included in twice\n",
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205000, 400)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hymc/[0]Github/Deeplearning-Autoencoder-DOA/[1]MATLAB/DOA_DATA/8_antenna_500_samples_100_snapshots\n",
      "/home/hymc/[0]Github/Deeplearning-Autoencoder-DOA/[3]Pytorch/[1]DOA_implementation/result/8_antenna_500_samples_100_snapshots\n"
     ]
    }
   ],
   "source": [
    "fileName = '8_antenna_500_samples_100_snapshots'\n",
    "\n",
    "dataPath = '/home/hymc/[0]Github/Deeplearning-Autoencoder-DOA/[1]MATLAB/DOA_DATA'\n",
    "\n",
    "\n",
    "readPath = dataPath +'/' + fileName\n",
    "print(readPath)\n",
    "\n",
    "rootPath = '/home/hymc/[0]Github/Deeplearning-Autoencoder-DOA/[3]Pytorch/[1]DOA_implementation'\n",
    "savePath = rootPath + '/result' + '/' + fileName\n",
    "if not os.path.isdir(savePath):\n",
    "    os.makedirs(savePath)\n",
    "print(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import torch\n",
    "data, target = make_classification(n_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset): \n",
    "    def __init__(self,data,target):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        current_sample = self.data[idx,:]\n",
    "        current_target = self.target[idx]\n",
    "        return {\n",
    "            'sample': torch.tensor(current_sample, dtype=torch.float),\n",
    "            'target': torch.tensor(current_target,dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataset = CustomDataset(data=data, target = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(custom_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataset[0]['sample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input train noisy dataset for all snr and stack them together\n",
    "dataset = tf.data.Dataset.list_files(fileName+'/*/train/train_data.*', shuffle=False)\n",
    "# for i in dataset.as_numpy_iterator():\n",
    "#     print(i)\n",
    "data_set = []\n",
    "for i in dataset.as_numpy_iterator():\n",
    "    x_train = sio.loadmat(i)\n",
    "    x_train = x_train['train_data']  # noisy sample covariance matrix\n",
    "    data_set.append(x_train) #NOTE: put all the train_data of different SNR into one list\n",
    "len(data_set) \n",
    "\n",
    "data_train = data_set[0]\n",
    "for i in data_set:\n",
    "    data_train = np.vstack((data_train,i)) # stack all the datasets vertically\n",
    "    \n",
    "data_train = data_train[x_train.shape[0]:] # the first dataset is included in twice\n",
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input train noiseless dataset for all snr and stack them together\n",
    "dataset = tf.data.Dataset.list_files(fileName + '/*/train/train_origin_data.*', shuffle=False)\n",
    "# for i in dataset.as_numpy_iterator():\n",
    "#     print(i)\n",
    "data_set = []\n",
    "for i in dataset.as_numpy_iterator():\n",
    "    x_train = sio.loadmat(i)\n",
    "    x_train = x_train['train_origin_data']  # noisy sample covariance matrix\n",
    "    data_set.append(x_train[:x_train.shape[0],:]) #NOTE: put all the train_data of different SNR into one list\n",
    "len(data_set) \n",
    "\n",
    "data_origin = data_set[0]\n",
    "for i in data_set:\n",
    "    data_origin = np.vstack((data_origin,i)) # stack all the datasets vertically\n",
    "    \n",
    "data_origin = data_origin[x_train.shape[0]:] # the first dataset is included in twice\n",
    "data_origin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data shuffle\n",
    "np.random.seed(2020)\n",
    "index = np.arange(data_train.shape[0])\n",
    "print(index)\n",
    "np.random.shuffle(index)\n",
    "data_train = data_train[index]\n",
    "data_origin = data_origin[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## scaling\n",
    "scaler = StandardScaler()\n",
    "data_train_scale = scaler.fit_transform(np.transpose(data_train))\n",
    "data_origin_scale = scaler.fit_transform(np.transpose(data_origin))\n",
    "print(data_train_scale.shape)\n",
    "print(data_origin_scale.shape)\n",
    "data_train = np.transpose(data_train_scale)\n",
    "data_origin = np.transpose(data_origin_scale)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Transforms images to a PyTorch Tensor\n",
    "# # transform = transforms.Compose(\n",
    "# #     [transforms.ToTensor(),\n",
    "# #     transforms.Normalize((0.5,),(0.5,))]) #NOTE: change the range of the data from 0 to 1 TO -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for i in range(len(data_train)):\n",
    "    dataset.append((data_train[i],data_origin[i]))\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# # Create data loaders.\n",
    "train_dataloader = DataLoader(dataset = dataset, \n",
    "                              batch_size = batch_size,\n",
    "                              shuffle = True)\n",
    "# test_dataloader = DataLoader(dataset = data_origin, \n",
    "#                              batch_size=batch_size,\n",
    "#                              shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for X in test_dataloader:\n",
    "#     print(f\"Shape of X [Batch size, Channel, Height, Width]: {X.shape}\")\n",
    "#     # print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "#     print(f'The maximum value is {torch.max(X)} and minimum value is {torch.min(X)}')\n",
    "#     break\n",
    "for X,Y in train_dataloader:\n",
    "    print(f\"Shape of X [Batch size, Channel, Height, Width]: {X.shape}\")\n",
    "    print(f\"Shape of Y: {Y.shape} {Y.dtype}\")\n",
    "    print(f'The maximum value is {torch.max(X)} and minimum value is {torch.min(X)}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Autoencoder Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a PyTorch class\n",
    "class AE_dense(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE_dense,self).__init__()\n",
    "        # Building an linear encoder with Linear\n",
    "        # layer followed by Relu activation function\n",
    "        # 400 ==> 100\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8), # 400, 300, 200, 100\n",
    "            nn.ReLU(),\n",
    "            # nn.Linear(100, 50),\n",
    "            # nn.ReLU()\n",
    "        )\n",
    "          \n",
    "        # Building an linear decoder with Linear\n",
    "        # layer followed by Relu activation function\n",
    "        # The Sigmoid activation function\n",
    "        # outputs the value between 0 and 1\n",
    "        # 100 ==> 400\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            # nn.Linear(50, 100), \n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(8, 16),  # 100, 200, 300, 400\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "        )\n",
    "  \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded, encoded,  \n",
    "    #! NOTE! when calling model(data), it returns a tuple (decoded, encoded). \n",
    "    #! Or you can just choose the first value for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "    def __init__(self,shape):\n",
    "        super(Reshape,self).__init__()\n",
    "        self.shape = shape\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x.view(*self.shape) #NOTE: '*' passes multiple parameters(but here with or without * returns the same value)\n",
    "        \n",
    "\n",
    "# Creating a PyTorch class\n",
    "class AE_conv(torch.nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(AE_conv,self).__init__()\n",
    "        # Building a convolution encoder with convolutional\n",
    "        # layer followed by Relu activation function\n",
    "        # 400 ==> 100\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride = 2, padding=1), # 28 * 28 -> 14 * 14\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride = 2, padding=1), # 14 * 14 -> 7 * 7\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Flatten(), # Image grid to single feature vector\n",
    "            nn.Linear(7*7*64, latent_dim), # second argument: latent_dim\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "          \n",
    "        # Building an convolution decoder with convolutional\n",
    "        # layer followed by Relu activation function\n",
    "        # The Sigmoid activation function\n",
    "        # outputs the value between 0 and 1\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim,7*7*64),\n",
    "            nn.LeakyReLU(),\n",
    "            Reshape((-1,64,7,7)),\n",
    "            nn.ConvTranspose2d(64,32,2, stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(32,1,2, stride=2),\n",
    "            nn.Tanh())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded, encoded,  \n",
    "    #! NOTE! when calling model(data), it returns a tuple (decoded, encoded). \n",
    "    #! Or you can just choose the first value for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "latent_dim = 10\n",
    "\n",
    "# Model Initialization\n",
    "model = AE_dense().to(device)\n",
    "# model = AE_conv(latent_dim).to(device)\n",
    "  \n",
    "# Validation using MSE Loss function\n",
    "loss_fn = torch.nn.MSELoss().to(device)\n",
    "  \n",
    "# Using an Adam Optimizer with lr = 0.1\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr = 1e-2,\n",
    "                             weight_decay = 1e-8)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,threshold = 0.1,patience=10,mode='min',verbose=True)\n",
    "# summary(model, (1, 28*28))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(dataloader, model, epoch):\n",
    "    '''Plot the original and reconstructed images together\n",
    "\n",
    "    Args:\n",
    "        dataloader (data_loader): an object that wraps the dataset\n",
    "        model (model): autoencoder\n",
    "    '''\n",
    "    model.eval() #Tell the model you are going to test so the weights will not be updated\n",
    "    with torch.no_grad():\n",
    "        for i, X in enumerate(dataloader):\n",
    "            # X = X.view(X.size(0), -1)\n",
    "            X = X.type(torch.FloatTensor).to(device) # to is one of the operations(methods) in tensor object\n",
    "\n",
    "            pred = model(X)\n",
    "            reconstructed = pred[0]\n",
    "            \n",
    "            # plot part\n",
    "            fig, axs = plt.subplots(2,1, figsize=(20,5)) # 2 means two rows\n",
    "            # display the original image\n",
    "            axs[0].plot(X.cpu()) ##Note axs is a matrix, you can't just write axs[], it should be axs[][]\n",
    "            # display the reconstructed image\n",
    "            axs[1].plot(reconstructed.cpu())\n",
    "\n",
    "            plt.savefig(savePath+ f'/epoch-{epoch}.png')\n",
    "            break\n",
    "    return fig\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, dataset,model, loss_fn, optimizer, scheduler):\n",
    "    size = len(dataset.dataset) # return the number of training samples\n",
    "    model.train() #Tell the model you are going to train so the weights will be updated\n",
    "    for t in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        # print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        for batch, (X,Y) in enumerate(dataset): # iterates the dataloader \n",
    "            # X = X.view(X.size(0),-1)\n",
    "            X = X.type(torch.FloatTensor).to(device)\n",
    "            Y = Y.type(torch.FloatTensor).to(device)\n",
    "\n",
    "            # Compute prediction error\n",
    "            pred = model(X) #! NOTE: Here the returned value is a tuple (decoded, encoded) as defined in forward()\n",
    "           \n",
    "            loss = loss_fn(pred[0], Y) # Choose the first value pred[0] as decoded value for the purpose of training\n",
    "                                        #! NOTE: the second argument should be the original value\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad() # to reset the gradients of model parameters.\n",
    "            loss.backward() # PyTorch deposits the gradients of the loss w.r.t. each parameter.\n",
    "            optimizer.step() # to adjust the parameters by the gradients collected in the backward pass.\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            # if batch % 100 == 0:\n",
    "            #     loss, current = loss.item(), batch * len(X)\n",
    "            #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        # .. log the running loss\n",
    "        writer.add_scalar('training_loss',\n",
    "                            running_loss/size,\n",
    "                            t)\n",
    "        # writer.add_figure('predictions vs. actuals',\n",
    "        #                 show(testdata, model, t, 10),\n",
    "        #                 global_step=t)\n",
    "        # for name, param in model.named_parameters():\n",
    "        #     layer, attr = os.path.splitext(name)\n",
    "        #     attr = attr[1:]\n",
    "        #     writer.add_histogram(f'{layer, attr}', param.clone().cpu().data.numpy(),t)\n",
    "        scheduler.step(loss)\n",
    "        # show(testdata, model, t,10)\n",
    "        print('Epoch: {}, Loss: {}, LR: {}'.format(t, running_loss/size, scheduler.optimizer.state_dict()['param_groups'][0]['lr']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Start training and validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "train(epochs, train_dataloader, model, loss_fn, optimizer,scheduler)\n",
    "writer.flush()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")\n",
    "\n",
    "# load model\n",
    "# model = NeuralNetwork()\n",
    "# model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Input/Reconstructed Input to/from Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input test noisy dataset for all snr and stack them together\n",
    "dataset = tf.data.Dataset.list_files(fileName + '/-10dB/test/test_data.*', shuffle=False)\n",
    "# for i in dataset.as_numpy_iterator():\n",
    "#     print(i)\n",
    "data_set = []\n",
    "for i in dataset.as_numpy_iterator():\n",
    "    x_train = sio.loadmat(i)\n",
    "    x_train = x_train['test_data']  # noisy sample covariance matrix\n",
    "    data_set.append(x_train) #NOTE: put all the train_data of different SNR into one list\n",
    "\n",
    "data_test = data_set[0]\n",
    "for i in data_set:\n",
    "    data_test = np.vstack((data_test,i)) # stack all the datasets vertically\n",
    "data_test = data_test[x_train.shape[0]:] # the first dataset is included in twice\n",
    "print(data_test.shape)\n",
    "\n",
    "# scaling\n",
    "# data_test = scaler.fit_transform(data_test)\n",
    "data_test_scale = scaler.fit_transform(np.transpose(data_test))\n",
    "# print(data_test_scale.shape)\n",
    "data_test = np.transpose(data_test_scale)\n",
    "# print(data_test.shape)\n",
    "\n",
    "# export data for MATLAB processing\n",
    "print(savePath)\n",
    "savePath_ = savePath + '/test_data.mat'\n",
    "print(savePath_)\n",
    "savemat(savePath_, {'test_data':data_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input test label dataset for all snr and stack them together\n",
    "dataset = tf.data.Dataset.list_files(fileName + '/-10dB/test/test_label.*', shuffle=False)\n",
    "# for i in dataset.as_numpy_iterator():\n",
    "#     print(i)\n",
    "data_set = []\n",
    "for i in dataset.as_numpy_iterator():\n",
    "    x_train = sio.loadmat(i)\n",
    "    x_train = x_train['test_label']  # noisy sample covariance matrix\n",
    "    data_set.append(x_train) #NOTE: put all the train_data of different SNR into one list\n",
    "len(data_set) \n",
    "data_label = data_set[0]\n",
    "for i in data_set:\n",
    "    data_label = np.vstack((data_label,i)) # stack all the datasets vertically\n",
    "data_label = data_label[x_train.shape[0]:] # the first dataset is included in twice\n",
    "data_label.shape\n",
    "\n",
    "print(savePath)\n",
    "savePath_ = savePath + '/test_label.mat'\n",
    "print(savePath_)\n",
    "savemat(savePath_, {'test_label':data_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstructedValue(X, model):\n",
    "    '''Plot the original and reconstructed images together\n",
    "\n",
    "    Args:\n",
    "        X (test data): test dataset\n",
    "        model (model): autoencoder\n",
    "    '''\n",
    "    model.eval() #Tell the model you are going to test so the weights will not be updated\n",
    "    with torch.no_grad():\n",
    "        X = torch.from_numpy(X) # change to numpy\n",
    "        X = X.type(torch.FloatTensor).to(device) # to is one of the operations(methods) in tensor object\n",
    "\n",
    "        pred = model(X)\n",
    "        reconstructed = pred[0]\n",
    "    \n",
    "    return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_data = reconstructedValue(data_test,model)\n",
    "print(decoded_data.shape)\n",
    "decoded_data = decoded_data.cpu().numpy()\n",
    "# Save the denoised data for MATLAB processing\n",
    "print(savePath)\n",
    "savePath_ = savePath + '/denoised_data.mat'\n",
    "print(savePath_)\n",
    "savemat(savePath_, {'denoised_data':decoded_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 40\n",
    "plt.plot(data_test[ind],'b')\n",
    "plt.plot(decoded_data[ind],'k')\n",
    "plt.fill_between(np.arange(64),decoded_data[ind],data_test[ind],color='lightcoral')\n",
    "plt.legend([\"Input\", \"Reconstruction\",\"Error\"])\n",
    "# plt.savefig('SNR_-30_autoencoder_compare.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF TEST DATA\n",
    "x_test = sio.loadmat('vec')\n",
    "test_max = x_test['vec']\n",
    "test_max = test_max.reshape(1,64)\n",
    "\n",
    "# scaling\n",
    "# data_test = scaler.fit_transform(data_test)\n",
    "test_max_scale = scaler.fit_transform(np.transpose(test_max))\n",
    "# print(data_test_scale.shape)\n",
    "test_data = np.transpose(test_max_scale)\n",
    "# print(data_test.shape)\n",
    "\n",
    "# export data for MATLAB processing\n",
    "print(savePath)\n",
    "savePath_ = savePath + '/test_data.mat'\n",
    "print(savePath_)\n",
    "savemat(savePath_, {'test_data':test_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_data = reconstructedValue(data_test,model)\n",
    "print(decoded_data.shape)\n",
    "\n",
    "# Save the denoised data for MATLAB processing\n",
    "print(savePath)\n",
    "savePath_ = savePath + '/denoised_data.mat'\n",
    "print(savePath_)\n",
    "savemat(savePath_, {'denoised_data':decoded_data})"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7b48e2873f2bf9fc322f66cbce100259936f291e167d1f147f978241de7630e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('basic_NN_study')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
