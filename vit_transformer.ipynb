{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (14x128 and 48x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\HYPC300\\OneDrive - 한양대학교\\GitHub\\Deeplearning-Autoencoder-DOA\\vit_transformer.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 147>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/HYPC300/OneDrive%20-%20%ED%95%9C%EC%96%91%EB%8C%80%ED%95%99%EA%B5%90/GitHub/Deeplearning-Autoencoder-DOA/vit_transformer.ipynb#ch0000000?line=144'>145</a>\u001b[0m model \u001b[39m=\u001b[39m IPT(traj_size\u001b[39m=\u001b[39m\u001b[39m224\u001b[39m,seg_size\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m,num_coordinate\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m,dim\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m,depth\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,heads\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,mlp_dim\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m)\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/HYPC300/OneDrive%20-%20%ED%95%9C%EC%96%91%EB%8C%80%ED%95%99%EA%B5%90/GitHub/Deeplearning-Autoencoder-DOA/vit_transformer.ipynb#ch0000000?line=145'>146</a>\u001b[0m traj_CSI \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m1\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m224\u001b[39m)\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/HYPC300/OneDrive%20-%20%ED%95%9C%EC%96%91%EB%8C%80%ED%95%99%EA%B5%90/GitHub/Deeplearning-Autoencoder-DOA/vit_transformer.ipynb#ch0000000?line=146'>147</a>\u001b[0m out \u001b[39m=\u001b[39m model(traj_CSI)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pt1.11\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/HYPC300/anaconda3/envs/pt1.11/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/HYPC300/anaconda3/envs/pt1.11/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/HYPC300/anaconda3/envs/pt1.11/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/HYPC300/anaconda3/envs/pt1.11/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/HYPC300/anaconda3/envs/pt1.11/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/HYPC300/anaconda3/envs/pt1.11/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/HYPC300/anaconda3/envs/pt1.11/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\HYPC300\\OneDrive - 한양대학교\\GitHub\\Deeplearning-Autoencoder-DOA\\vit_transformer.ipynb Cell 1'\u001b[0m in \u001b[0;36mIPT.forward\u001b[1;34m(self, traj_CSI)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/HYPC300/OneDrive%20-%20%ED%95%9C%EC%96%91%EB%8C%80%ED%95%99%EA%B5%90/GitHub/Deeplearning-Autoencoder-DOA/vit_transformer.ipynb#ch0000000?line=125'>126</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, traj_CSI):\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/HYPC300/OneDrive%20-%20%ED%95%9C%EC%96%91%EB%8C%80%ED%95%99%EA%B5%90/GitHub/Deeplearning-Autoencoder-DOA/vit_transformer.ipynb#ch0000000?line=126'>127</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mto_seg_embedding(traj_CSI)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/HYPC300/OneDrive%20-%20%ED%95%9C%EC%96%91%EB%8C%80%ED%95%99%EA%B5%90/GitHub/Deeplearning-Autoencoder-DOA/vit_transformer.ipynb#ch0000000?line=127'>128</a>\u001b[0m     b, n, _ \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape \u001b[39m# b: batch size, n: channel (number of the antennas)\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/HYPC300/OneDrive%20-%20%ED%95%9C%EC%96%91%EB%8C%80%ED%95%99%EA%B5%90/GitHub/Deeplearning-Autoencoder-DOA/vit_transformer.ipynb#ch0000000?line=129'>130</a>\u001b[0m     pos_tokens \u001b[39m=\u001b[39m repeat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_token, \u001b[39m'\u001b[39m\u001b[39m() n d -> b n d\u001b[39m\u001b[39m'\u001b[39m, b \u001b[39m=\u001b[39m b)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pt1.11\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/HYPC300/anaconda3/envs/pt1.11/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/HYPC300/anaconda3/envs/pt1.11/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/HYPC300/anaconda3/envs/pt1.11/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/HYPC300/anaconda3/envs/pt1.11/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/HYPC300/anaconda3/envs/pt1.11/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/HYPC300/anaconda3/envs/pt1.11/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/HYPC300/anaconda3/envs/pt1.11/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pt1.11\\lib\\site-packages\\torch\\nn\\modules\\container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/HYPC300/anaconda3/envs/pt1.11/lib/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/HYPC300/anaconda3/envs/pt1.11/lib/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/HYPC300/anaconda3/envs/pt1.11/lib/site-packages/torch/nn/modules/container.py?line=140'>141</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    <a href='file:///c%3A/Users/HYPC300/anaconda3/envs/pt1.11/lib/site-packages/torch/nn/modules/container.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pt1.11\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/HYPC300/anaconda3/envs/pt1.11/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/HYPC300/anaconda3/envs/pt1.11/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/HYPC300/anaconda3/envs/pt1.11/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/HYPC300/anaconda3/envs/pt1.11/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/HYPC300/anaconda3/envs/pt1.11/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/HYPC300/anaconda3/envs/pt1.11/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/HYPC300/anaconda3/envs/pt1.11/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pt1.11\\lib\\site-packages\\torch\\nn\\modules\\linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/HYPC300/anaconda3/envs/pt1.11/lib/site-packages/torch/nn/modules/linear.py?line=101'>102</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> <a href='file:///c%3A/Users/HYPC300/anaconda3/envs/pt1.11/lib/site-packages/torch/nn/modules/linear.py?line=102'>103</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (14x128 and 48x128)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "from torch import nn\n",
    "\n",
    "# helpers\n",
    "\n",
    "def pair(t):\n",
    "    return t if isinstance(t, tuple) else (t, t)\n",
    "\n",
    "# classes\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.attend = nn.Softmax(dim = -1)\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n",
    "\n",
    "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
    "\n",
    "        attn = self.attend(dots)\n",
    "\n",
    "        out = torch.matmul(attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                PreNorm(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout)),\n",
    "                PreNorm(dim, FeedForward(dim, mlp_dim, dropout = dropout))\n",
    "            ]))\n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "        return x\n",
    "\n",
    "class IPT(nn.Module):\n",
    "    def __init__(self, *, traj_size, seg_size, num_coordinate, dim, depth, heads, mlp_dim, pool = 'position', channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0.):\n",
    "        '''Generating the IPS transformer\n",
    "        Args:\n",
    "            traj_size (int): the size of the trajectory CSI (1D)\n",
    "            seg_size (int): the size of the segmented part of a whole trajectory CSI (1D)\n",
    "            num_coordinate (int): use x and y to represent the position\n",
    "            dim (int): the embedding dimension (I think it can be used to shrink the input size)\n",
    "            depth (int): the number of encoder in the encoder layer\n",
    "            heads (int): the number of heads in the multihead attention case\n",
    "            mlp_dim (int): multilayyer perceptron, to set up the number of neurons in the linear layer of FeedForward layer\n",
    "            pool (str, optional): define the inserted information type. Defaults to 'position'. (also consider add DOA information here)\n",
    "            channels (int, optional): (maybe) number of antennas. Defaults to 3.\n",
    "            dim_head (int, optional): the dimension of the Q,K,V matrices. Defaults to 64. (I guess the reason why the head_dim is divisible by embedding dimension is that when you concatenate the result of the three heads, the size of the the concatenated vector is the same as the input vector)\n",
    "            dropout (int, optional): dropout rate used in feedforward layer . Defaults to 0..\n",
    "            emb_dropout (int, optional): dropout rate used in embedding layer. Defaults to 0.. (not so sure why the embedding layer also needs dropout)\n",
    "        '''\n",
    "        super().__init__()\n",
    "        assert traj_size % seg_size == 0, 'The dimension of the trajectory CSI must be divisible by the segmentation size.'\n",
    "        num_seg = traj_size // seg_size # // means floor operation\n",
    "        \n",
    "        ## IPS: divide the CSI of one traj into \n",
    "        # patch_dim = channels * patch_height * patch_width (3D)\n",
    "        seg_dim = channels * seg_size #(2D)\n",
    "        #IPS: the position shall be inserted at the beginning of the trajectory CSI\n",
    "        assert pool in {'cls', 'mean', 'position'}, 'pool type must be either cls (cls token) or mean (mean pooling) or position '\n",
    "\n",
    "        # b: means the batch size, which may be the number of trajectories\n",
    "        self.to_seg_embedding = nn.Sequential(\n",
    "            # Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),\n",
    "            Rearrange('b c (h s) -> b h (s c)', s = seg_size),\n",
    "            nn.Linear(seg_dim, dim), # I guess this linear layer will shrink the input dimension to embedding dim\n",
    "        )\n",
    "\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_seg + 1, dim)) #NOTE the position embedding chosen to be trainable\n",
    "        self.pos_token = nn.Parameter(torch.randn(1, 1, dim)) #! pos_token is the KEY for IPS, adding the position information to the input\n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n",
    "\n",
    "        self.pool = pool\n",
    "        self.to_latent = nn.Identity() # DOING NOTHING JUST COPY THE INPUT TO THE OUTPUT\n",
    "\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, num_coordinate) #! here the code needs to be modified\n",
    "        )\n",
    "\n",
    "    def forward(self, traj_CSI):\n",
    "        x = self.to_seg_embedding(traj_CSI)\n",
    "        b, n, _ = x.shape # b: batch size, n: channel (number of the antennas)\n",
    "\n",
    "        pos_tokens = repeat(self.pos_token, '() n d -> b n d', b = b)\n",
    "        x = torch.cat((pos_tokens, x), dim=1) #! IPS: Concatenate the position information to the begining of the trajectory CSI\n",
    "        x += self.pos_embedding[:, :(n + 1)] # Add the positional embedding\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        # x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n",
    "        x = x[:,:2] if self.pool == 'position' else x[:, 0]\n",
    "\n",
    "        x = self.to_latent(x)\n",
    "        return self.mlp_head(x)\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = IPT(traj_size=224,seg_size=16,num_coordinate=4,dim=128,depth=1,heads=2,mlp_dim=1024).cuda()\n",
    "traj_CSI = torch.randn(1, 8, 224).cuda()\n",
    "out = model(traj_CSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0044,  0.8776, -1.4038, -1.2487],\n",
      "        [-0.1700, -1.5702, -0.8470,  0.4614],\n",
      "        [ 0.5038, -0.7697,  1.4915,  0.6889]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0044,  0.8776],\n",
       "        [-0.1700, -1.5702],\n",
       "        [ 0.5038, -0.7697]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3,4)\n",
    "print(a)\n",
    "a[:,:2]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50c7fc28387dacebb05d87680c8f08467fac81d942eb9a8ef147de8479f54731"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pt1.11')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
