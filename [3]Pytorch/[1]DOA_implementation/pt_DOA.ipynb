{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-01 15:57:06.938525: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
      "2022-03-01 15:57:06.938544: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt*\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import tensorflow as tf\n",
    "import scipy.io as sio\n",
    "from scipy.io import loadmat, savemat\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hymc/[0]Github/Deeplearning-Autoencoder-DOA/[1]MATLAB/DOA_DATA/8_antenna_500_samples_100_snapshots\n",
      "/home/hymc/[0]Github/Deeplearning-Autoencoder-DOA/[3]Pytorch/[1]DOA_implementation/result/8_antenna_500_samples_100_snapshots\n"
     ]
    }
   ],
   "source": [
    "fileName = '8_antenna_500_samples_100_snapshots'\n",
    "\n",
    "dataPath = '/home/hymc/[0]Github/Deeplearning-Autoencoder-DOA/[1]MATLAB/DOA_DATA'\n",
    "\n",
    "\n",
    "readPath = dataPath +'/' + fileName\n",
    "print(readPath)\n",
    "\n",
    "rootPath = '/home/hymc/[0]Github/Deeplearning-Autoencoder-DOA/[3]Pytorch/[1]DOA_implementation'\n",
    "savePath = rootPath + '/result' + '/' + fileName\n",
    "if not os.path.isdir(savePath):\n",
    "    os.makedirs(savePath)\n",
    "print(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import torch\n",
    "data, target = make_classification(n_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset): \n",
    "    def __init__(self,data,target):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        current_sample = self.data[idx,:]\n",
    "        current_target = self.target[idx]\n",
    "        return {\n",
    "            'sample': torch.tensor(current_sample, dtype=torch.float),\n",
    "            'target': torch.tensor(current_target,dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataset = CustomDataset(data=data, target = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(custom_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.5089,  1.2295,  0.8938, -1.7735,  0.4042, -0.8870,  0.3304,  2.8960,\n",
       "        -0.4011,  0.0598, -1.3440, -0.1048, -1.3017, -1.8702,  1.5285,  3.4140,\n",
       "         0.6177,  0.6557, -1.1345,  0.2220])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_dataset[0]['sample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102500, 64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input train noisy dataset for all snr and stack them together\n",
    "dataset = tf.data.Dataset.list_files(fileName+'/*/train/train_data.*', shuffle=False)\n",
    "# for i in dataset.as_numpy_iterator():\n",
    "#     print(i)\n",
    "data_set = []\n",
    "for i in dataset.as_numpy_iterator():\n",
    "    x_train = sio.loadmat(i)\n",
    "    x_train = x_train['train_data']  # noisy sample covariance matrix\n",
    "    data_set.append(x_train) #NOTE: put all the train_data of different SNR into one list\n",
    "len(data_set) \n",
    "\n",
    "data_train = data_set[0]\n",
    "for i in data_set:\n",
    "    data_train = np.vstack((data_train,i)) # stack all the datasets vertically\n",
    "    \n",
    "data_train = data_train[x_train.shape[0]:] # the first dataset is included in twice\n",
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102500, 64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input train noiseless dataset for all snr and stack them together\n",
    "dataset = tf.data.Dataset.list_files(fileName + '/*/train/train_origin_data.*', shuffle=False)\n",
    "# for i in dataset.as_numpy_iterator():\n",
    "#     print(i)\n",
    "data_set = []\n",
    "for i in dataset.as_numpy_iterator():\n",
    "    x_train = sio.loadmat(i)\n",
    "    x_train = x_train['train_origin_data']  # noisy sample covariance matrix\n",
    "    data_set.append(x_train[:x_train.shape[0],:]) #NOTE: put all the train_data of different SNR into one list\n",
    "len(data_set) \n",
    "\n",
    "data_origin = data_set[0]\n",
    "for i in data_set:\n",
    "    data_origin = np.vstack((data_origin,i)) # stack all the datasets vertically\n",
    "    \n",
    "data_origin = data_origin[x_train.shape[0]:] # the first dataset is included in twice\n",
    "data_origin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     0      1      2 ... 102497 102498 102499]\n"
     ]
    }
   ],
   "source": [
    "# train data shuffle\n",
    "np.random.seed(2020)\n",
    "index = np.arange(data_train.shape[0])\n",
    "print(index)\n",
    "np.random.shuffle(index)\n",
    "data_train = data_train[index]\n",
    "data_origin = data_origin[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 102500)\n",
      "(64, 102500)\n"
     ]
    }
   ],
   "source": [
    "## scaling\n",
    "scaler = StandardScaler()\n",
    "data_train_scale = scaler.fit_transform(np.transpose(data_train))\n",
    "data_origin_scale = scaler.fit_transform(np.transpose(data_origin))\n",
    "print(data_train_scale.shape)\n",
    "print(data_origin_scale.shape)\n",
    "data_train = np.transpose(data_train_scale)\n",
    "data_origin = np.transpose(data_origin_scale)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Transforms images to a PyTorch Tensor\n",
    "# # transform = transforms.Compose(\n",
    "# #     [transforms.ToTensor(),\n",
    "# #     transforms.Normalize((0.5,),(0.5,))]) #NOTE: change the range of the data from 0 to 1 TO -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for i in range(len(data_train)):\n",
    "    dataset.append((data_train[i],data_origin[i]))\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# # Create data loaders.\n",
    "train_dataloader = DataLoader(dataset = dataset, \n",
    "                              batch_size = batch_size,\n",
    "                              shuffle = True)\n",
    "# test_dataloader = DataLoader(dataset = data_origin, \n",
    "#                              batch_size=batch_size,\n",
    "#                              shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [Batch size, Channel, Height, Width]: torch.Size([64, 64])\n",
      "Shape of Y: torch.Size([64, 64]) torch.float64\n",
      "The maximum value is 3.278346244787716 and minimum value is -1.6546467371601095\n"
     ]
    }
   ],
   "source": [
    "# for X in test_dataloader:\n",
    "#     print(f\"Shape of X [Batch size, Channel, Height, Width]: {X.shape}\")\n",
    "#     # print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "#     print(f'The maximum value is {torch.max(X)} and minimum value is {torch.min(X)}')\n",
    "#     break\n",
    "for X,Y in train_dataloader:\n",
    "    print(f\"Shape of X [Batch size, Channel, Height, Width]: {X.shape}\")\n",
    "    print(f\"Shape of Y: {Y.shape} {Y.dtype}\")\n",
    "    print(f'The maximum value is {torch.max(X)} and minimum value is {torch.min(X)}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Autoencoder Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a PyTorch class\n",
    "class AE_dense(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE_dense,self).__init__()\n",
    "        # Building an linear encoder with Linear\n",
    "        # layer followed by Relu activation function\n",
    "        # 400 ==> 100\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8), # 400, 300, 200, 100\n",
    "            nn.ReLU(),\n",
    "            # nn.Linear(100, 50),\n",
    "            # nn.ReLU()\n",
    "        )\n",
    "          \n",
    "        # Building an linear decoder with Linear\n",
    "        # layer followed by Relu activation function\n",
    "        # The Sigmoid activation function\n",
    "        # outputs the value between 0 and 1\n",
    "        # 100 ==> 400\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            # nn.Linear(50, 100), \n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(8, 16),  # 100, 200, 300, 400\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "        )\n",
    "  \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded, encoded,  \n",
    "    #! NOTE! when calling model(data), it returns a tuple (decoded, encoded). \n",
    "    #! Or you can just choose the first value for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "    def __init__(self,shape):\n",
    "        super(Reshape,self).__init__()\n",
    "        self.shape = shape\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x.view(*self.shape) #NOTE: '*' passes multiple parameters(but here with or without * returns the same value)\n",
    "        \n",
    "\n",
    "# Creating a PyTorch class\n",
    "class AE_conv(torch.nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(AE_conv,self).__init__()\n",
    "        # Building a convolution encoder with convolutional\n",
    "        # layer followed by Relu activation function\n",
    "        # 400 ==> 100\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride = 2, padding=1), # 28 * 28 -> 14 * 14\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride = 2, padding=1), # 14 * 14 -> 7 * 7\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Flatten(), # Image grid to single feature vector\n",
    "            nn.Linear(7*7*64, latent_dim), # second argument: latent_dim\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "          \n",
    "        # Building an convolution decoder with convolutional\n",
    "        # layer followed by Relu activation function\n",
    "        # The Sigmoid activation function\n",
    "        # outputs the value between 0 and 1\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim,7*7*64),\n",
    "            nn.LeakyReLU(),\n",
    "            Reshape((-1,64,7,7)),\n",
    "            nn.ConvTranspose2d(64,32,2, stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(32,1,2, stride=2),\n",
    "            nn.Tanh())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded, encoded,  \n",
    "    #! NOTE! when calling model(data), it returns a tuple (decoded, encoded). \n",
    "    #! Or you can just choose the first value for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "latent_dim = 10\n",
    "\n",
    "# Model Initialization\n",
    "model = AE_dense().to(device)\n",
    "# model = AE_conv(latent_dim).to(device)\n",
    "  \n",
    "# Validation using MSE Loss function\n",
    "loss_fn = torch.nn.MSELoss().to(device)\n",
    "  \n",
    "# Using an Adam Optimizer with lr = 0.1\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr = 1e-2,\n",
    "                             weight_decay = 1e-8)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,threshold = 0.1,patience=10,mode='min',verbose=True)\n",
    "# summary(model, (1, 28*28))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hymc/[0]Github/Deeplearning-Autoencoder-DOA/[3]Pytorch/[1]DOA_implementation/result/with_normalization\n"
     ]
    }
   ],
   "source": [
    "def show(dataloader, model, epoch):\n",
    "    '''Plot the original and reconstructed images together\n",
    "\n",
    "    Args:\n",
    "        dataloader (data_loader): an object that wraps the dataset\n",
    "        model (model): autoencoder\n",
    "    '''\n",
    "    model.eval() #Tell the model you are going to test so the weights will not be updated\n",
    "    with torch.no_grad():\n",
    "        for i, X in enumerate(dataloader):\n",
    "            # X = X.view(X.size(0), -1)\n",
    "            X = X.type(torch.FloatTensor).to(device) # to is one of the operations(methods) in tensor object\n",
    "\n",
    "            pred = model(X)\n",
    "            reconstructed = pred[0]\n",
    "            \n",
    "            # plot part\n",
    "            fig, axs = plt.subplots(2,1, figsize=(20,5)) # 2 means two rows\n",
    "            # display the original image\n",
    "            axs[0].plot(X.cpu()) ##Note axs is a matrix, you can't just write axs[], it should be axs[][]\n",
    "            # display the reconstructed image\n",
    "            axs[1].plot(reconstructed.cpu())\n",
    "\n",
    "            plt.savefig(savePath+ f'/epoch-{epoch}.png')\n",
    "            break\n",
    "    return fig\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, dataset,model, loss_fn, optimizer, scheduler):\n",
    "    size = len(dataset.dataset) # return the number of training samples\n",
    "    model.train() #Tell the model you are going to train so the weights will be updated\n",
    "    for t in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        # print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        for batch, (X,Y) in enumerate(dataset): # iterates the dataloader \n",
    "            # X = X.view(X.size(0),-1)\n",
    "            X = X.type(torch.FloatTensor).to(device)\n",
    "            Y = Y.type(torch.FloatTensor).to(device)\n",
    "\n",
    "            # Compute prediction error\n",
    "            pred = model(X) #! NOTE: Here the returned value is a tuple (decoded, encoded) as defined in forward()\n",
    "           \n",
    "            loss = loss_fn(pred[0], Y) # Choose the first value pred[0] as decoded value for the purpose of training\n",
    "                                        #! NOTE: the second argument should be the original value\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad() # to reset the gradients of model parameters.\n",
    "            loss.backward() # PyTorch deposits the gradients of the loss w.r.t. each parameter.\n",
    "            optimizer.step() # to adjust the parameters by the gradients collected in the backward pass.\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            # if batch % 100 == 0:\n",
    "            #     loss, current = loss.item(), batch * len(X)\n",
    "            #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        # .. log the running loss\n",
    "        writer.add_scalar('training_loss',\n",
    "                            running_loss/size,\n",
    "                            t)\n",
    "        # writer.add_figure('predictions vs. actuals',\n",
    "        #                 show(testdata, model, t, 10),\n",
    "        #                 global_step=t)\n",
    "        # for name, param in model.named_parameters():\n",
    "        #     layer, attr = os.path.splitext(name)\n",
    "        #     attr = attr[1:]\n",
    "        #     writer.add_histogram(f'{layer, attr}', param.clone().cpu().data.numpy(),t)\n",
    "        scheduler.step(loss)\n",
    "        # show(testdata, model, t,10)\n",
    "        print('Epoch: {}, Loss: {}, LR: {}'.format(t, running_loss/size, scheduler.optimizer.state_dict()['param_groups'][0]['lr']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Start training and validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.0023592733120046012, LR: 0.01\n",
      "Epoch: 1, Loss: 0.001618131673190652, LR: 0.01\n",
      "Epoch: 2, Loss: 0.001556221686994157, LR: 0.01\n",
      "Epoch: 3, Loss: 0.0015299019357053246, LR: 0.01\n",
      "Epoch: 4, Loss: 0.0015007883757352828, LR: 0.01\n",
      "Epoch: 5, Loss: 0.0014869157056982924, LR: 0.01\n",
      "Epoch: 6, Loss: 0.00147144741234256, LR: 0.01\n",
      "Epoch: 7, Loss: 0.0014599820946047946, LR: 0.01\n",
      "Epoch: 8, Loss: 0.0014503075798110263, LR: 0.01\n",
      "Epoch: 9, Loss: 0.0014506302153918802, LR: 0.01\n",
      "Epoch: 10, Loss: 0.0014360243595227962, LR: 0.01\n",
      "Epoch: 11, Loss: 0.0014345138146383007, LR: 0.01\n",
      "Epoch: 12, Loss: 0.0014307263598209473, LR: 0.01\n",
      "Epoch: 13, Loss: 0.0014249568925398153, LR: 0.01\n",
      "Epoch: 14, Loss: 0.001417346787961518, LR: 0.01\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch: 15, Loss: 0.001417860414923691, LR: 0.001\n",
      "Epoch: 16, Loss: 0.0013316161151339368, LR: 0.001\n",
      "Epoch: 17, Loss: 0.0013265526011949633, LR: 0.001\n",
      "Epoch: 18, Loss: 0.0013242621426175281, LR: 0.001\n",
      "Epoch: 19, Loss: 0.0013233627392751416, LR: 0.001\n",
      "Epoch: 20, Loss: 0.0013224208112896942, LR: 0.001\n",
      "Epoch: 21, Loss: 0.0013208504689902795, LR: 0.001\n",
      "Epoch: 22, Loss: 0.0013198004056040834, LR: 0.001\n",
      "Epoch: 23, Loss: 0.0013180241769406853, LR: 0.001\n",
      "Epoch: 24, Loss: 0.00131765706335626, LR: 0.001\n",
      "Epoch: 25, Loss: 0.0013168599981360318, LR: 0.001\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 26, Loss: 0.0013171509730379755, LR: 0.0001\n",
      "Epoch: 27, Loss: 0.001306533023569642, LR: 0.0001\n",
      "Epoch: 28, Loss: 0.0013053166438166688, LR: 0.0001\n",
      "Epoch: 29, Loss: 0.0013053519764324513, LR: 0.0001\n",
      "Epoch: 30, Loss: 0.0013052799200139395, LR: 0.0001\n",
      "Epoch: 31, Loss: 0.0013051179911305266, LR: 0.0001\n",
      "Epoch: 32, Loss: 0.0013048910922393566, LR: 0.0001\n",
      "Epoch: 33, Loss: 0.0013046809490860963, LR: 0.0001\n",
      "Epoch: 34, Loss: 0.0013046864255899337, LR: 0.0001\n",
      "Epoch: 35, Loss: 0.001304573809809801, LR: 0.0001\n",
      "Epoch: 36, Loss: 0.0013045437945098412, LR: 0.0001\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch: 37, Loss: 0.0013044072111932242, LR: 1e-05\n",
      "Epoch: 38, Loss: 0.0013032472375689482, LR: 1e-05\n",
      "Epoch: 39, Loss: 0.0013030848036452037, LR: 1e-05\n",
      "Epoch: 40, Loss: 0.001303033250788363, LR: 1e-05\n",
      "Epoch: 41, Loss: 0.0013029446484112159, LR: 1e-05\n",
      "Epoch: 42, Loss: 0.0013030548632144928, LR: 1e-05\n",
      "Epoch: 43, Loss: 0.0013030304346869632, LR: 1e-05\n",
      "Epoch: 44, Loss: 0.0013029675355044807, LR: 1e-05\n",
      "Epoch: 45, Loss: 0.001302994860018172, LR: 1e-05\n",
      "Epoch: 46, Loss: 0.0013029705081044173, LR: 1e-05\n",
      "Epoch: 47, Loss: 0.001302969930157429, LR: 1e-05\n",
      "Epoch: 48, Loss: 0.0013028333805683182, LR: 1e-05\n",
      "Epoch: 49, Loss: 0.0013029954706750264, LR: 1e-05\n",
      "Epoch: 50, Loss: 0.0013029764538857996, LR: 1e-05\n",
      "Epoch: 51, Loss: 0.0013029458173164506, LR: 1e-05\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch: 52, Loss: 0.0013028829887145902, LR: 1.0000000000000002e-06\n",
      "Epoch: 53, Loss: 0.0013028005102785623, LR: 1.0000000000000002e-06\n",
      "Epoch: 54, Loss: 0.0013026976959007541, LR: 1.0000000000000002e-06\n",
      "Epoch: 55, Loss: 0.0013027284862791619, LR: 1.0000000000000002e-06\n",
      "Epoch: 56, Loss: 0.0013028051754323448, LR: 1.0000000000000002e-06\n",
      "Epoch: 57, Loss: 0.0013028549645732088, LR: 1.0000000000000002e-06\n",
      "Epoch: 58, Loss: 0.0013027985495765034, LR: 1.0000000000000002e-06\n",
      "Epoch: 59, Loss: 0.0013027405735923023, LR: 1.0000000000000002e-06\n",
      "Epoch: 60, Loss: 0.0013026554564150368, LR: 1.0000000000000002e-06\n",
      "Epoch: 61, Loss: 0.0013027259579518947, LR: 1.0000000000000002e-06\n",
      "Epoch: 62, Loss: 0.0013027290603736552, LR: 1.0000000000000002e-06\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch: 63, Loss: 0.0013027632609373186, LR: 1.0000000000000002e-07\n",
      "Epoch: 64, Loss: 0.0013028193162708747, LR: 1.0000000000000002e-07\n",
      "Epoch: 65, Loss: 0.001302741695613396, LR: 1.0000000000000002e-07\n",
      "Epoch: 66, Loss: 0.00130260202579382, LR: 1.0000000000000002e-07\n",
      "Epoch: 67, Loss: 0.0013026630623311532, LR: 1.0000000000000002e-07\n",
      "Epoch: 68, Loss: 0.0013028067005116765, LR: 1.0000000000000002e-07\n",
      "Epoch: 69, Loss: 0.001302730520033255, LR: 1.0000000000000002e-07\n",
      "Epoch: 70, Loss: 0.0013028455701543063, LR: 1.0000000000000002e-07\n",
      "Epoch: 71, Loss: 0.0013027410023823017, LR: 1.0000000000000002e-07\n",
      "Epoch: 72, Loss: 0.0013028134534271753, LR: 1.0000000000000002e-07\n",
      "Epoch: 73, Loss: 0.0013026992267224846, LR: 1.0000000000000002e-07\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch: 74, Loss: 0.001302714074821007, LR: 1.0000000000000004e-08\n",
      "Epoch: 75, Loss: 0.0013027094133743426, LR: 1.0000000000000004e-08\n",
      "Epoch: 76, Loss: 0.0013026883600688562, LR: 1.0000000000000004e-08\n",
      "Epoch: 77, Loss: 0.0013026207650580057, LR: 1.0000000000000004e-08\n",
      "Epoch: 78, Loss: 0.0013026667602905413, LR: 1.0000000000000004e-08\n",
      "Epoch: 79, Loss: 0.0013027016282081605, LR: 1.0000000000000004e-08\n",
      "Epoch: 80, Loss: 0.0013027184806945846, LR: 1.0000000000000004e-08\n",
      "Epoch: 81, Loss: 0.0013027241810065944, LR: 1.0000000000000004e-08\n",
      "Epoch: 82, Loss: 0.0013025994417870917, LR: 1.0000000000000004e-08\n",
      "Epoch: 83, Loss: 0.001302627539198573, LR: 1.0000000000000004e-08\n",
      "Epoch: 84, Loss: 0.0013027853730975128, LR: 1.0000000000000004e-08\n",
      "Epoch: 85, Loss: 0.0013027853470023085, LR: 1.0000000000000004e-08\n",
      "Epoch: 86, Loss: 0.0013027024948742332, LR: 1.0000000000000004e-08\n",
      "Epoch: 87, Loss: 0.0013027436117573482, LR: 1.0000000000000004e-08\n",
      "Epoch: 88, Loss: 0.0013026435916743627, LR: 1.0000000000000004e-08\n",
      "Epoch: 89, Loss: 0.0013027601311119592, LR: 1.0000000000000004e-08\n",
      "Epoch: 90, Loss: 0.0013026889803932934, LR: 1.0000000000000004e-08\n",
      "Epoch: 91, Loss: 0.001302633124226477, LR: 1.0000000000000004e-08\n",
      "Epoch: 92, Loss: 0.001302635886974451, LR: 1.0000000000000004e-08\n",
      "Epoch: 93, Loss: 0.0013027209474546152, LR: 1.0000000000000004e-08\n",
      "Epoch: 94, Loss: 0.0013025791658860882, LR: 1.0000000000000004e-08\n",
      "Epoch: 95, Loss: 0.0013027502418291278, LR: 1.0000000000000004e-08\n",
      "Epoch: 96, Loss: 0.0013029245279184201, LR: 1.0000000000000004e-08\n",
      "Epoch: 97, Loss: 0.0013027861619141043, LR: 1.0000000000000004e-08\n",
      "Epoch: 98, Loss: 0.0013027227049193732, LR: 1.0000000000000004e-08\n",
      "Epoch: 99, Loss: 0.0013026819268377816, LR: 1.0000000000000004e-08\n",
      "Epoch: 100, Loss: 0.0013026317539738446, LR: 1.0000000000000004e-08\n",
      "Epoch: 101, Loss: 0.001302781743538089, LR: 1.0000000000000004e-08\n",
      "Epoch: 102, Loss: 0.0013027599257666891, LR: 1.0000000000000004e-08\n",
      "Epoch: 103, Loss: 0.0013026600701052968, LR: 1.0000000000000004e-08\n",
      "Epoch: 104, Loss: 0.0013026873313799136, LR: 1.0000000000000004e-08\n",
      "Epoch: 105, Loss: 0.0013027284580759886, LR: 1.0000000000000004e-08\n",
      "Epoch: 106, Loss: 0.001302687270321497, LR: 1.0000000000000004e-08\n",
      "Epoch: 107, Loss: 0.0013027716479650359, LR: 1.0000000000000004e-08\n",
      "Epoch: 108, Loss: 0.0013027652798629388, LR: 1.0000000000000004e-08\n",
      "Epoch: 109, Loss: 0.001302771002344969, LR: 1.0000000000000004e-08\n",
      "Epoch: 110, Loss: 0.001302757400419654, LR: 1.0000000000000004e-08\n",
      "Epoch: 111, Loss: 0.0013028233866866042, LR: 1.0000000000000004e-08\n",
      "Epoch: 112, Loss: 0.0013026925032458654, LR: 1.0000000000000004e-08\n",
      "Epoch: 113, Loss: 0.0013026403855986711, LR: 1.0000000000000004e-08\n",
      "Epoch: 114, Loss: 0.0013029132630766893, LR: 1.0000000000000004e-08\n",
      "Epoch: 115, Loss: 0.0013027820757249506, LR: 1.0000000000000004e-08\n",
      "Epoch: 116, Loss: 0.0013026408995070109, LR: 1.0000000000000004e-08\n",
      "Epoch: 117, Loss: 0.0013027903354022562, LR: 1.0000000000000004e-08\n",
      "Epoch: 118, Loss: 0.0013026307090753463, LR: 1.0000000000000004e-08\n",
      "Epoch: 119, Loss: 0.0013027414137270392, LR: 1.0000000000000004e-08\n",
      "Epoch: 120, Loss: 0.0013027318676070469, LR: 1.0000000000000004e-08\n",
      "Epoch: 121, Loss: 0.0013026684680363027, LR: 1.0000000000000004e-08\n",
      "Epoch: 122, Loss: 0.0013027564778560546, LR: 1.0000000000000004e-08\n",
      "Epoch: 123, Loss: 0.0013027348828751866, LR: 1.0000000000000004e-08\n",
      "Epoch: 124, Loss: 0.0013027401948120536, LR: 1.0000000000000004e-08\n",
      "Epoch: 125, Loss: 0.0013026670759044043, LR: 1.0000000000000004e-08\n",
      "Epoch: 126, Loss: 0.0013027744461850423, LR: 1.0000000000000004e-08\n",
      "Epoch: 127, Loss: 0.0013027148355798024, LR: 1.0000000000000004e-08\n",
      "Epoch: 128, Loss: 0.0013027131688304063, LR: 1.0000000000000004e-08\n",
      "Epoch: 129, Loss: 0.0013027208852331813, LR: 1.0000000000000004e-08\n",
      "Epoch: 130, Loss: 0.0013026741483589499, LR: 1.0000000000000004e-08\n",
      "Epoch: 131, Loss: 0.001302739425766759, LR: 1.0000000000000004e-08\n",
      "Epoch: 132, Loss: 0.0013028334515850718, LR: 1.0000000000000004e-08\n",
      "Epoch: 133, Loss: 0.0013028160290747153, LR: 1.0000000000000004e-08\n",
      "Epoch: 134, Loss: 0.001302707157847358, LR: 1.0000000000000004e-08\n",
      "Epoch: 135, Loss: 0.0013026274688360169, LR: 1.0000000000000004e-08\n",
      "Epoch: 136, Loss: 0.0013028021433731404, LR: 1.0000000000000004e-08\n",
      "Epoch: 137, Loss: 0.001302727879983623, LR: 1.0000000000000004e-08\n",
      "Epoch: 138, Loss: 0.0013027023204216144, LR: 1.0000000000000004e-08\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [81]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m writer\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[0;32mIn [80]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epochs, dataset, model, loss_fn, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     18\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad() \u001b[38;5;66;03m# to reset the gradients of model parameters.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m# PyTorch deposits the gradients of the loss w.r.t. each parameter.\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# to adjust the parameters by the gradients collected in the backward pass.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# if batch % 100 == 0:\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m#     loss, current = loss.item(), batch * len(X)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m#     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# .. log the running loss\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pt/lib/python3.8/site-packages/torch/optim/optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pt/lib/python3.8/site-packages/torch/autograd/grad_mode.py:28\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m():\n\u001b[0;32m---> 28\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pt/lib/python3.8/site-packages/torch/optim/adam.py:133\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[38;5;66;03m# record the step after step update\u001b[39;00m\n\u001b[1;32m    131\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 133\u001b[0m     \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m           \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m           \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m           \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m           \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m           \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m           \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m           \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m           \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m           \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m           \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/envs/pt/lib/python3.8/site-packages/torch/optim/_functional.py:86\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     83\u001b[0m     grad \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39madd(param, alpha\u001b[38;5;241m=\u001b[39mweight_decay)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amsgrad:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m# Maintains the maximum of all 2nd moment running avg. till now\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "train(epochs, train_dataloader, model, loss_fn, optimizer,scheduler)\n",
    "writer.flush()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")\n",
    "\n",
    "# load model\n",
    "# model = NeuralNetwork()\n",
    "# model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Input/Reconstructed Input to/from Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 64)\n",
      "/home/hymc/[0]Github/Deeplearning-Autoencoder-DOA/[3]Pytorch/[1]DOA_implementation/result/8_antenna_500_samples_100_snapshots\n",
      "/home/hymc/[0]Github/Deeplearning-Autoencoder-DOA/[3]Pytorch/[1]DOA_implementation/result/8_antenna_500_samples_100_snapshots/test_data.mat\n"
     ]
    }
   ],
   "source": [
    "# Input test noisy dataset for all snr and stack them together\n",
    "dataset = tf.data.Dataset.list_files(fileName + '/-10dB/test/test_data.*', shuffle=False)\n",
    "# for i in dataset.as_numpy_iterator():\n",
    "#     print(i)\n",
    "data_set = []\n",
    "for i in dataset.as_numpy_iterator():\n",
    "    x_train = sio.loadmat(i)\n",
    "    x_train = x_train['test_data']  # noisy sample covariance matrix\n",
    "    data_set.append(x_train) #NOTE: put all the train_data of different SNR into one list\n",
    "\n",
    "data_test = data_set[0]\n",
    "for i in data_set:\n",
    "    data_test = np.vstack((data_test,i)) # stack all the datasets vertically\n",
    "data_test = data_test[x_train.shape[0]:] # the first dataset is included in twice\n",
    "print(data_test.shape)\n",
    "\n",
    "# scaling\n",
    "# data_test = scaler.fit_transform(data_test)\n",
    "data_test_scale = scaler.fit_transform(np.transpose(data_test))\n",
    "# print(data_test_scale.shape)\n",
    "data_test = np.transpose(data_test_scale)\n",
    "# print(data_test.shape)\n",
    "\n",
    "# export data for MATLAB processing\n",
    "print(savePath)\n",
    "savePath_ = savePath + '/test_data.mat'\n",
    "print(savePath_)\n",
    "savemat(savePath_, {'test_data':data_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hymc/[0]Github/Deeplearning-Autoencoder-DOA/[3]Pytorch/[1]DOA_implementation/result/8_antenna_500_samples_100_snapshots\n",
      "/home/hymc/[0]Github/Deeplearning-Autoencoder-DOA/[3]Pytorch/[1]DOA_implementation/result/8_antenna_500_samples_100_snapshots/test_label.mat\n"
     ]
    }
   ],
   "source": [
    "# Input test label dataset for all snr and stack them together\n",
    "dataset = tf.data.Dataset.list_files(fileName + '/-10dB/test/test_label.*', shuffle=False)\n",
    "# for i in dataset.as_numpy_iterator():\n",
    "#     print(i)\n",
    "data_set = []\n",
    "for i in dataset.as_numpy_iterator():\n",
    "    x_train = sio.loadmat(i)\n",
    "    x_train = x_train['test_label']  # noisy sample covariance matrix\n",
    "    data_set.append(x_train) #NOTE: put all the train_data of different SNR into one list\n",
    "len(data_set) \n",
    "data_label = data_set[0]\n",
    "for i in data_set:\n",
    "    data_label = np.vstack((data_label,i)) # stack all the datasets vertically\n",
    "data_label = data_label[x_train.shape[0]:] # the first dataset is included in twice\n",
    "data_label.shape\n",
    "\n",
    "print(savePath)\n",
    "savePath_ = savePath + '/test_label.mat'\n",
    "print(savePath_)\n",
    "savemat(savePath_, {'test_label':data_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstructedValue(X, model):\n",
    "    '''Plot the original and reconstructed images together\n",
    "\n",
    "    Args:\n",
    "        X (test data): test dataset\n",
    "        model (model): autoencoder\n",
    "    '''\n",
    "    model.eval() #Tell the model you are going to test so the weights will not be updated\n",
    "    with torch.no_grad():\n",
    "        X = torch.from_numpy(X) # change to numpy\n",
    "        X = X.type(torch.FloatTensor).to(device) # to is one of the operations(methods) in tensor object\n",
    "\n",
    "        pred = model(X)\n",
    "        reconstructed = pred[0]\n",
    "    \n",
    "    return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 64])\n",
      "/home/hymc/[0]Github/Deeplearning-Autoencoder-DOA/[3]Pytorch/[1]DOA_implementation/result/8_antenna_500_samples_100_snapshots\n",
      "/home/hymc/[0]Github/Deeplearning-Autoencoder-DOA/[3]Pytorch/[1]DOA_implementation/result/8_antenna_500_samples_100_snapshots/denoised_data.mat\n"
     ]
    }
   ],
   "source": [
    "decoded_data = reconstructedValue(data_test,model)\n",
    "print(decoded_data.shape)\n",
    "decoded_data = decoded_data.cpu().numpy()\n",
    "# Save the denoised data for MATLAB processing\n",
    "print(savePath)\n",
    "savePath_ = savePath + '/denoised_data.mat'\n",
    "print(savePath_)\n",
    "savemat(savePath_, {'denoised_data':decoded_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7cda90f0a0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = 40\n",
    "plt.plot(data_test[ind],'b')\n",
    "plt.plot(decoded_data[ind],'k')\n",
    "plt.fill_between(np.arange(64),decoded_data[ind],data_test[ind],color='lightcoral')\n",
    "plt.legend([\"Input\", \"Reconstruction\",\"Error\"])\n",
    "# plt.savefig('SNR_-30_autoencoder_compare.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'vec.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/pt/lib/python3.8/site-packages/scipy/io/matlab/mio.py:39\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Probably \"not found\"\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'vec'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [57]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# RF TEST DATA\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m x_test \u001b[38;5;241m=\u001b[39m \u001b[43msio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvec\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m test_max \u001b[38;5;241m=\u001b[39m x_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvec\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m test_max \u001b[38;5;241m=\u001b[39m test_max\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m64\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pt/lib/python3.8/site-packages/scipy/io/matlab/mio.py:216\u001b[0m, in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03mLoad MATLAB file.\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;124;03m    3.14159265+3.14159265j])\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    215\u001b[0m variable_names \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariable_names\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    217\u001b[0m     MR, _ \u001b[38;5;241m=\u001b[39m mat_reader_factory(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    218\u001b[0m     matfile_dict \u001b[38;5;241m=\u001b[39m MR\u001b[38;5;241m.\u001b[39mget_variables(variable_names)\n",
      "File \u001b[0;32m~/anaconda3/envs/pt/lib/python3.8/contextlib.py:113\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/pt/lib/python3.8/site-packages/scipy/io/matlab/mio.py:19\u001b[0m, in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;129m@contextmanager\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_context\u001b[39m(file_like, appendmat, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 19\u001b[0m     f, opened \u001b[38;5;241m=\u001b[39m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappendmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m f\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m opened:\n",
      "File \u001b[0;32m~/anaconda3/envs/pt/lib/python3.8/site-packages/scipy/io/matlab/mio.py:45\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m appendmat \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_like\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     44\u001b[0m         file_like \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReader needs file name or open file-like object\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'vec.mat'"
     ]
    }
   ],
   "source": [
    "# RF TEST DATA\n",
    "x_test = sio.loadmat('vec')\n",
    "test_max = x_test['vec']\n",
    "test_max = test_max.reshape(1,64)\n",
    "\n",
    "# scaling\n",
    "# data_test = scaler.fit_transform(data_test)\n",
    "test_max_scale = scaler.fit_transform(np.transpose(test_max))\n",
    "# print(data_test_scale.shape)\n",
    "test_data = np.transpose(test_max_scale)\n",
    "# print(data_test.shape)\n",
    "\n",
    "# export data for MATLAB processing\n",
    "print(savePath)\n",
    "savePath_ = savePath + '/test_data.mat'\n",
    "print(savePath_)\n",
    "savemat(savePath_, {'test_data':test_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_data = reconstructedValue(data_test,model)\n",
    "print(decoded_data.shape)\n",
    "\n",
    "# Save the denoised data for MATLAB processing\n",
    "print(savePath)\n",
    "savePath_ = savePath + '/denoised_data.mat'\n",
    "print(savePath_)\n",
    "savemat(savePath_, {'denoised_data':decoded_data})"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7b48e2873f2bf9fc322f66cbce100259936f291e167d1f147f978241de7630e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('basic_NN_study')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
